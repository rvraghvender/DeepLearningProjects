{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNHEfkGklxd1CEuZzSKw3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvraghvender/DeepLearningProjects/blob/main/ConvolutionNeuralNetworks/NerualArtGeneration/Art_Generation_with_Neural_Style_Transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning & Art: Neural Style Transfer"
      ],
      "metadata": {
        "id": "_pG60XP-3Kfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Packages\n"
      ],
      "metadata": {
        "id": "kIASA3Hk3SQd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "00DcHlM03BfY"
      },
      "outputs": [],
      "source": [
        "# Importing relevant packages\n",
        "import os\n",
        "import sys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as imshow\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "import pprint\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Problem Statement\n",
        "\n",
        "Nerual Style Transfer (NST) is one of the most fun and interesting optimzation techniques in deep learing. It merges two images, namely a **\"content\" image (C)** and **\"style\" image (S)**, to create a **\"generated\" image (G) **. The generated image G combines the \"content\" of the image C with the \"style\" of image S.\n",
        "\n",
        "In this assignment, we are going to cobine the Louvre museum in Paris (content image, C) with the impressionist style of Claude Monet (content image S) to generate the following image:\n",
        "\n",
        "<img src=\"https://github.com/rvraghvender/DeepLearningProjects/blob/main/ConvolutionNeuralNetworks/NerualArtGeneration/images/louvre_generated.png?raw=true\" style=\"width:750px;height:200px;\">\n",
        "\n",
        "Let's get started!\n"
      ],
      "metadata": {
        "id": "A0a2llkT33jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning\n",
        "Neural Style  Transfer (NST) uses a previously tranied convolution network, and builds on top of that. The idea of using a network trained on a different task and applying it to a new task is called transfer learning.\n",
        "\n",
        "We will be using the epynomously named VGG network from the [original NST paper](https://arxiv.org/abs/1508.06576) published by the Visual Geometry Group at University of Oxford in 2014. Specifically, we'll use VGG-19, a 19-layer version of the VGG network. This model has already been tranied on the very large ImageNet database, and has learned to recoginze a variety of low level features (at the shallow layers) and high level features (at the deeper layer).\n",
        "\n",
        "Run the below code to load parameters from the VGG model."
      ],
      "metadata": {
        "id": "4ye3-xZQ5suG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(272) # To be consistent with different tries\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "img_size = 400\n",
        "vgg = tf.keras.applications.VGG19(include_top=False,\n",
        "                                  input_shape=(img_size, img_size, 3),\n",
        "                                  weights='pretrained-model/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "vgg.trainable = False\n",
        "pp.pprint(vgg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "5xftvsT23uKZ",
        "outputId": "dd0d9b2c-9a39-4973-e01f-0d9a32353d4a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5486759f324f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrettyPrinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m vgg = tf.keras.applications.VGG19(include_top=False,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                   \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                   weights='pretrained-model/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/applications/vgg19.py\u001b[0m in \u001b[0;36mVGG19\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \"\"\"\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;34m\"The `weights` argument should be either \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;34m\"`None` (random initialization), `imagenet` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `weights` argument should be either `None` (random initialization), `imagenet` (pre-training on ImageNet), or the path to the weights file to be loaded.  Received: `weights=pretrained-model/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5.`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G9UFvm2Q7Xr1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}